{"cells":[{"cell_type":"markdown","metadata":{"id":"ktFg2jj3jTE6"},"source":["# ACTIVIDAD 3: Deep Learning para Clasificación de Texto "]},{"cell_type":"markdown","metadata":{"id":"MZ-OuW5DiLJs"},"source":["En esta actividad vamos a trabajar en clasificar textos. Se recorrerá todo el proceso desde traer el dataset hasta proceder a dicha clasificación. Durante la actividad se llevarán a cabo muchos procesos como la creación de un vocabulario, el uso de embeddings y la creación de modelos.\n","\n","Las cuestiones presentes en esta actividad están basadas en un Notebook creado por François Chollet, uno de los creadores de Keras y autor del libro \"Deep Learning with Python\". \n","\n","En este Notebook se trabaja con el dataset \"Newsgroup20\" que contiene aproximadamente 20000 mensajes que pertenecen a 20 categorías diferentes.\n","\n","El objetivo es entender los conceptos que se trabajan y ser capaz de hacer pequeñas experimentaciones para mejorar el Notebook creado."]},{"cell_type":"code","source":["#Basado en:\n","#https://keras.io/examples/nlp/pretrained_word_embeddings/"],"metadata":{"id":"Ytpb1W-imjkg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hytURWLLjZvT"},"source":["#Librerías"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"DbxRuvOwkzSs","executionInfo":{"status":"ok","timestamp":1685984361765,"user_tz":-120,"elapsed":2821,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras"]},{"cell_type":"markdown","metadata":{"id":"PXfYbCflkQYy"},"source":["# Descarga de Datos"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"e-1ZhOf3lB_A","executionInfo":{"status":"ok","timestamp":1685984410608,"user_tz":-120,"elapsed":29363,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e5ec6abe-458f-486b-f1f1-ffa499953bdc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\n","17329808/17329808 [==============================] - 22s 1us/step\n"]}],"source":["data_path = keras.utils.get_file(\n","    \"news20.tar.gz\",\n","    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",\n","    untar=True,\n",")"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"l3ygvoWhlCYj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685984410608,"user_tz":-120,"elapsed":11,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}},"outputId":"b1dbb4f6-99f5-4896-df8d-a151108d3e85"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of directories: 20\n","Directory names: ['talk.politics.misc', 'rec.autos', 'sci.electronics', 'rec.sport.hockey', 'talk.politics.guns', 'misc.forsale', 'sci.med', 'comp.sys.ibm.pc.hardware', 'comp.os.ms-windows.misc', 'comp.sys.mac.hardware', 'rec.sport.baseball', 'rec.motorcycles', 'sci.space', 'soc.religion.christian', 'sci.crypt', 'comp.graphics', 'talk.politics.mideast', 'alt.atheism', 'talk.religion.misc', 'comp.windows.x']\n"]}],"source":["import os\n","import pathlib\n","\n","#Estructura de directorios del dataset\n","data_dir = pathlib.Path(data_path).parent / \"20_newsgroup\"\n","dirnames = os.listdir(data_dir)\n","print(\"Number of directories:\", len(dirnames))\n","print(\"Directory names:\", dirnames)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"OG8rjgOFlcaV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685984410609,"user_tz":-120,"elapsed":11,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}},"outputId":"99f449e4-0b94-47bf-f3b5-2dde43229026"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of files in comp.graphics: 1000\n","Some example filenames: ['37917', '38287', '37261', '38991', '38782']\n"]}],"source":["#Algunos archivos de la categoria \"com.graphics\"\n","fnames = os.listdir(data_dir / \"comp.graphics\")\n","print(\"Number of files in comp.graphics:\", len(fnames))\n","print(\"Some example filenames:\", fnames[:5])"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"8ox6s6z9lgps","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685984410609,"user_tz":-120,"elapsed":9,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}},"outputId":"dcba7620-654b-4b4c-fed4-55130b7cc565"},"outputs":[{"output_type":"stream","name":"stdout","text":["Path: cantaloupe.srv.cs.cmu.edu!rochester!udel!gatech!howland.reston.ans.net!newsserver.jvnc.net!castor.hahnemann.edu!hal.hahnemann.edu!brennan\n","From: brennan@hal.hahnemann.edu\n","Newsgroups: comp.graphics\n","Subject: .GIFs on a Tek401x ??\n","Date: 15 MAY 93 14:29:54 EST\n","Organization: Hahnemann University\n","Lines: 14\n","Message-ID: <15MAY93.14295461@hal.hahnemann.edu>\n","NNTP-Posting-Host: hal.hahnemann.edu\n","\n","\n","      I was skimming through a few gophers and bumped into one at NIH\n","   with a database that included images in .GIF format.  While I have\n","   not yet worked out the kinks of getting the gopher client to call\n","   an X viewer, I figure that the majority of the users here are not\n","   in an X11 environment - instead using DOS and MS-Kermit.\n","\n","      With Kermit supporting Tek4010 emulation for graphics display,\n","   does anyone know of a package that would allow a Tek to display a\n","   .GIF image?  It would be of more use to the local population to\n","   plug something of this sort in as the 'picture' command instead of\n","   XView or XLoadImage ...\n","\n","      andrew.  (brennan@hal.hahnemann.edu)\n","\n"]}],"source":["#Ejemplo de un texto de la categoría \"com.graphics\"\n","print(open(data_dir / \"comp.graphics\" / \"39625\").read())"]},{"cell_type":"markdown","source":["<font color='green'>**Pregunta 1 (0.5 puntos): Escribe un texto de la categoría 'sci.electronics'**</font>"],"metadata":{"id":"Tx3-RRHZik6N"}},{"cell_type":"code","source":["#Tu respuesta aqui\n","fnames = os.listdir(data_dir / \"sci.electronics\")\n","print(\"Ejemplo sci.electronics :\", fnames[0])\n","print(open(data_dir / \"sci.electronics\" / fnames[0]).read())\n"],"metadata":{"id":"mFQ3AuODij9h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685984410609,"user_tz":-120,"elapsed":7,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}},"outputId":"ebcbcac4-f226-4cf4-ce4c-541bccd87bdc"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Ejemplo sci.electronics : 54333\n","Path: cantaloupe.srv.cs.cmu.edu!magnesium.club.cc.cmu.edu!pitt.edu!dsinc!ub!acsu.buffalo.edu!ubvmsb.cc.buffalo.edu!v064mb9k\n","From: v064mb9k@ubvmsb.cc.buffalo.edu (NEIL B. GANDLER)\n","Newsgroups: sci.electronics\n","Subject: Looking for a good book on Pspice 5.2\n","Message-ID: <C65EGz.BG1@acsu.buffalo.edu>\n","Date: 27 Apr 93 15:19:00 GMT\n","Sender: nntp@acsu.buffalo.edu\n","Organization: University at Buffalo\n","Lines: 6\n","News-Software: VAX/VMS VNEWS 1.41\n","Nntp-Posting-Host: ubvmsb.cc.buffalo.edu\n","\n","\n","\tI just got a copy of spice 5.2. I would like to know if there are\n","any published books on the market yet and where I could get one. I would\n","appreciate any help. Thank You\n","\n","\t\tNeil Gandler\n","\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"id":"33Ay5U6blCd1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685984411806,"user_tz":-120,"elapsed":1202,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}},"outputId":"794fe6f8-d09c-49af-8f94-a7dfac868207"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processing alt.atheism, 1000 files found\n","Processing comp.graphics, 1000 files found\n","Processing comp.os.ms-windows.misc, 1000 files found\n","Processing comp.sys.ibm.pc.hardware, 1000 files found\n","Processing comp.sys.mac.hardware, 1000 files found\n","Processing comp.windows.x, 1000 files found\n","Processing misc.forsale, 1000 files found\n","Processing rec.autos, 1000 files found\n","Processing rec.motorcycles, 1000 files found\n","Processing rec.sport.baseball, 1000 files found\n","Processing rec.sport.hockey, 1000 files found\n","Processing sci.crypt, 1000 files found\n","Processing sci.electronics, 1000 files found\n","Processing sci.med, 1000 files found\n","Processing sci.space, 1000 files found\n","Processing soc.religion.christian, 997 files found\n","Processing talk.politics.guns, 1000 files found\n","Processing talk.politics.mideast, 1000 files found\n","Processing talk.politics.misc, 1000 files found\n","Processing talk.religion.misc, 1000 files found\n","Classes: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n","Number of samples: 19997\n"]}],"source":["samples = []\n","labels = []\n","class_names = []\n","class_index = 0\n","for dirname in sorted(os.listdir(data_dir)):\n","    class_names.append(dirname)\n","    dirpath = data_dir / dirname\n","    fnames = os.listdir(dirpath)\n","    print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\n","    for fname in fnames:\n","        fpath = dirpath / fname\n","        f = open(fpath, encoding=\"latin-1\")\n","        content = f.read()\n","        lines = content.split(\"\\n\")\n","        lines = lines[10:]\n","        content = \"\\n\".join(lines)\n","        samples.append(content)\n","        labels.append(class_index)\n","    class_index += 1\n","\n","print(\"Classes:\", class_names)\n","print(\"Number of samples:\", len(samples))"]},{"cell_type":"markdown","metadata":{"id":"n2pmvE6gMcxT"},"source":["# Mezclando los datos para separarlos en Traning y Test"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"DYX7x-k_lCgZ","executionInfo":{"status":"ok","timestamp":1685984412204,"user_tz":-120,"elapsed":400,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}}},"outputs":[],"source":["# Shuffle the data\n","seed = 1337\n","rng = np.random.RandomState(seed)\n","rng.shuffle(samples)\n","rng = np.random.RandomState(seed)\n","rng.shuffle(labels)\n","\n","# Extract a training & validation split\n","validation_split = 0.2\n","num_validation_samples = int(validation_split * len(samples))\n","train_samples = samples[:-num_validation_samples]\n","val_samples = samples[-num_validation_samples:]\n","train_labels = labels[:-num_validation_samples]\n","val_labels = labels[-num_validation_samples:]"]},{"cell_type":"markdown","metadata":{"id":"uMrE0T4wMj09"},"source":["<font color='green'>**Pregunta 2 (0.5 puntos): ¿Por qué mezclamos los datos antes de separarlos en entrenamiento y validación?**</font>"]},{"cell_type":"markdown","source":["<font color='green'>Tu respuesta aqui: \n","\n","Encontramos dos principales motivos:\n","\n","\n","Facilitar la validación cruzada: La mezcla de datos es esencial para aplicar técnicas como la validación cruzada, asegurando que cada subconjunto de entrenamiento y validación contenga una representación equilibrada y aleatoria de los datos.\n","\n","Evitar sesgos en la distribución de los datos: Al mezclar los datos, garantizamos que no haya un orden específico que pueda sesgar la distribución de los datos en los conjuntos de entrenamiento."],"metadata":{"id":"fZkWK2z_gF7V"}},{"cell_type":"markdown","source":["<font color='green'>**Pregunta 3 (1 punto): ¿Por qué estás seguro que en la \n","división aleatoria cada muestra coincide con su etiqueta correcta?**</font>"],"metadata":{"id":"FCPGWsdDjlIS"}},{"cell_type":"markdown","source":["<font color='green'>Tu respuesta aqui:\n","\n","A traves de la semilla 'seed' se utiliza para generar los instancias separadas de 'np.random.RandomState', asi nos aseguramos que tengan las mismas permutaciones aleatorias tanto para las muestra 'samples' como para las etiquetas 'labels'. Luego en la línea rng.shuffle(samples), se realiza la mezcla aleatoria de las muestras utilizando la primera instancia de RandomState.\n","\n","El código consigue que cada muestra coincida con su etiqueta correcta después de la división aleatoria."],"metadata":{"id":"IO_T4m27gLKs"}},{"cell_type":"markdown","metadata":{"id":"IktOtKfpNx8E"},"source":["# Tokenización de las palabras con TextVectorization "]},{"cell_type":"code","execution_count":9,"metadata":{"id":"QjHgQPX8lCjO","executionInfo":{"status":"ok","timestamp":1685984445200,"user_tz":-120,"elapsed":5269,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}}},"outputs":[],"source":["from tensorflow.keras.layers import TextVectorization\n","vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n","text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n","vectorizer.adapt(text_ds)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"vIWC37s5smZ4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685984445201,"user_tz":-120,"elapsed":20,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}},"outputId":"23f0e264-d3fa-494a-f3c1-a9a2580f303b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['', '[UNK]', 'the', 'to', 'of']"]},"metadata":{},"execution_count":10}],"source":["vectorizer.get_vocabulary()[:5]"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"vit8TPqTvmwS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685984445492,"user_tz":-120,"elapsed":307,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}},"outputId":"6ef13ec2-959a-4dec-c8b1-787d9c9fd3c8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["20000"]},"metadata":{},"execution_count":11}],"source":["len(vectorizer.get_vocabulary())"]},{"cell_type":"markdown","metadata":{"id":"Yttb9K8vssAz"},"source":["<font color='green'>**Pregunta 4 (2 puntos): En la construcción del vocabulario hemos limitado el número de tokens a 20.000 ¿Podrías indicar el número de token diferentes o tamaño del vocabulario sin limitar el número de tokens? Es decir, ¿Cuántas palabras diferentes existen en los documentos procesados como instancias?**</font>"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"SZIgywwYquDE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685985904529,"user_tz":-120,"elapsed":2849,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}},"outputId":"5ac4c97d-bf54-4f98-aacc-d98915432ee5"},"outputs":[{"output_type":"stream","name":"stdout","text":["156962\n"]}],"source":["#Tu código para responder a esta pregunta aqui:\n","# TextVectorization convierte cadenas de texto en listas de tokens y después convierte estas listas de tokens en listas de números\n","# Crear una instancia de TextVectorization. Sin límite en el número de palabras que se tienen en cuenta. Todas las secuencias de salida se rellenan hasta 200. Si son más largas se truncan.\n","vectorizer_2 = TextVectorization(max_tokens=None, output_sequence_length=200)\n","\n","# Objeto Dataset de TensorFlow en batches de 128.\n","text_ds_2 = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n","\n","# Crear un índice de palabras basado en las palabras que encuentran en los datos de entrenamiento.\n","# 'adapt' para hacer que el vectorizador \"aprenda\" el vocabulario de los datos de entrenamiento (contar la frecuencia de cada palabra en los datos y luego asignar un índice a cada palabra)\n","vectorizer_2.adapt(text_ds_2)\n","\n","print(len(vectorizer_2.get_vocabulary()))"]},{"cell_type":"markdown","metadata":{"id":"2O-FXA9wPVkg"},"source":["# Viendo la salida de Vectorizer"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"rseIF0fLmyJ0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685984449398,"user_tz":-120,"elapsed":194,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}},"outputId":"0c50309c-44c6-4df1-e85b-c2ab82114b9b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([   2, 3550, 1807,   15,    2, 5708])"]},"metadata":{},"execution_count":13}],"source":["output = vectorizer([[\"the cat sat on the mat\"]])\n","output.numpy()[0, :6]"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"Wsr4AQtBFArV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685984450243,"user_tz":-120,"elapsed":6,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}},"outputId":"501aa2ea-a891-4e28-d237-f802acefe543"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 200), dtype=int64, numpy=\n","array([[   2, 3550, 1807,   15,    2, 5708,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0]])>"]},"metadata":{},"execution_count":14}],"source":["output"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"SL5ag8UamzwL","executionInfo":{"status":"ok","timestamp":1685984452912,"user_tz":-120,"elapsed":359,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}}},"outputs":[],"source":["voc = vectorizer.get_vocabulary()\n","word_index = dict(zip(voc, range(len(voc))))"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"08v8SKcsn3lf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685984453479,"user_tz":-120,"elapsed":201,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}},"outputId":"10e7b5de-8662-406e-c765-2838598aa8e3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[2, 3550, 1807, 15, 2, 5708]"]},"metadata":{},"execution_count":16}],"source":["test = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n","[word_index[w] for w in test]"]},{"cell_type":"markdown","metadata":{"id":"rWxZ5Z0sF_d8"},"source":["<font color='green'>**Pregunta 5 (1 punto): Arriba tenemos la codificación de la frase \"the cat sat on the mat\". Imagina la siguiente situación. La salida de vectorizer() para codificar los tokens [\"El\", \"gato\", \"está\", \"sobre\", \"el\", \"tejado\"] es la siguiente [1, 121, 405, 1, 45, 4561]. Si cada uno de los valores indica el índice en el que se encuentra cada palabra en el array creado para codificarla. ¿Podría ser correcta esta salida?**</font>"]},{"cell_type":"markdown","source":["<font color='green'>Tu respuesta aqui: \n","\n","No podria ser correcta, por que despues de convertir a minusculas todas las palabras \"El\" y \"el\" tendran que tener el mismo número. Ya que tienen la misma frecuencia.\n","Está mal en este caso ya que en la primera posición \"El\" tiene el número 1 y en la quinta posición \"el\" tiene el 45."],"metadata":{"id":"lZ1HP2VngTdA"}},{"cell_type":"markdown","metadata":{"id":"1eBhadrvOTNZ"},"source":["# Tokenización de los datos de entrenamiento y validación"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"W26LUr2dKTOj","executionInfo":{"status":"ok","timestamp":1685984518151,"user_tz":-120,"elapsed":7364,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}}},"outputs":[],"source":["x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n","x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n","\n","y_train = np.array(train_labels)\n","y_val = np.array(val_labels)"]},{"cell_type":"markdown","source":["# Creación del modelo con un embedding hecho a mano y con redes neuronales convolucionales"],"metadata":{"id":"TGvYD56WlhaA"}},{"cell_type":"markdown","source":["Aunque las Redes Neuronales Convolucionales se desarrollaron originalmente para procesamiento de imágenes, se pueden aplicar a problemas de procesamiento de lenguaje natural gracias a su capacidad para capturar patrones locales y globales en los datos de entrada.\n","\n","Previa a la alimentación de las capas convolucionales, vamos a incluir una capa de Embedding. Como hemos visto en clase, un embedding de palabras se refiere a una representación vectorial densa de una palabra en un espacio de características continuo de alta dimensión. Como resultado del embedding vamos capturar la semántica de las palabras de manera que palabras similares tengan representaciones vectoriales similares.\n","\n","A continuación se incluye la creación de un modelo con un embedding hecho a mano y usando  Redes Neuronales Convolucionales"],"metadata":{"id":"tI0TYBbvHNwr"}},{"cell_type":"code","execution_count":18,"metadata":{"id":"AT8KYdHaOh31","executionInfo":{"status":"ok","timestamp":1685984518152,"user_tz":-120,"elapsed":3,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}}},"outputs":[],"source":["modeloEmbeddingManualConvolucionales = keras.models.Sequential()\n","modeloEmbeddingManualConvolucionales.add(keras.layers.Embedding(20000, 10, input_length=200))\n","modeloEmbeddingManualConvolucionales.add(keras.layers.Conv1D(128, 5, activation=\"relu\"))\n","modeloEmbeddingManualConvolucionales.add(keras.layers.MaxPooling1D(5))\n","modeloEmbeddingManualConvolucionales.add(keras.layers.Conv1D(128, 5, activation=\"relu\"))\n","modeloEmbeddingManualConvolucionales.add(keras.layers.MaxPooling1D(5))\n","modeloEmbeddingManualConvolucionales.add(keras.layers.Conv1D(128, 5, activation=\"relu\"))\n","modeloEmbeddingManualConvolucionales.add(keras.layers.GlobalMaxPooling1D())\n","modeloEmbeddingManualConvolucionales.add(keras.layers.Dense(128, activation='relu'))\n","modeloEmbeddingManualConvolucionales.add(keras.layers.Dropout(0.3))\n","modeloEmbeddingManualConvolucionales.add(keras.layers.Dense(20, activation='softmax'))"]},{"cell_type":"code","source":["modeloEmbeddingManualConvolucionales.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","modeloEmbeddingManualConvolucionales.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n","modeloEmbeddingManualConvolucionales.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))"],"metadata":{"id":"xtx8L9hJm-lQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685984661124,"user_tz":-120,"elapsed":142974,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}},"outputId":"50500a12-3be5-4dd0-f617-be3f985e3b5f"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","125/125 [==============================] - 30s 148ms/step - loss: 2.9295 - acc: 0.0729 - val_loss: 2.6799 - val_acc: 0.1018\n","Epoch 2/20\n","125/125 [==============================] - 15s 119ms/step - loss: 2.5324 - acc: 0.1229 - val_loss: 2.3229 - val_acc: 0.1498\n","Epoch 3/20\n","125/125 [==============================] - 9s 69ms/step - loss: 2.2914 - acc: 0.1571 - val_loss: 2.1922 - val_acc: 0.1863\n","Epoch 4/20\n","125/125 [==============================] - 9s 71ms/step - loss: 2.1184 - acc: 0.2019 - val_loss: 2.0527 - val_acc: 0.2383\n","Epoch 5/20\n","125/125 [==============================] - 7s 56ms/step - loss: 1.9667 - acc: 0.2440 - val_loss: 2.0293 - val_acc: 0.2496\n","Epoch 6/20\n","125/125 [==============================] - 5s 39ms/step - loss: 1.8421 - acc: 0.2909 - val_loss: 1.8886 - val_acc: 0.2973\n","Epoch 7/20\n","125/125 [==============================] - 5s 39ms/step - loss: 1.6620 - acc: 0.3632 - val_loss: 1.7327 - val_acc: 0.3666\n","Epoch 8/20\n","125/125 [==============================] - 5s 38ms/step - loss: 1.4807 - acc: 0.4256 - val_loss: 1.6425 - val_acc: 0.4076\n","Epoch 9/20\n","125/125 [==============================] - 4s 32ms/step - loss: 1.3099 - acc: 0.4991 - val_loss: 1.7444 - val_acc: 0.4164\n","Epoch 10/20\n","125/125 [==============================] - 4s 29ms/step - loss: 1.1659 - acc: 0.5623 - val_loss: 1.6050 - val_acc: 0.4596\n","Epoch 11/20\n","125/125 [==============================] - 4s 36ms/step - loss: 1.0489 - acc: 0.6146 - val_loss: 1.5080 - val_acc: 0.5034\n","Epoch 12/20\n","125/125 [==============================] - 4s 30ms/step - loss: 0.9511 - acc: 0.6580 - val_loss: 1.6060 - val_acc: 0.5261\n","Epoch 13/20\n","125/125 [==============================] - 2s 16ms/step - loss: 0.8712 - acc: 0.6890 - val_loss: 1.5332 - val_acc: 0.5416\n","Epoch 14/20\n","125/125 [==============================] - 2s 13ms/step - loss: 0.7935 - acc: 0.7193 - val_loss: 1.6675 - val_acc: 0.5414\n","Epoch 15/20\n","125/125 [==============================] - 3s 21ms/step - loss: 0.7343 - acc: 0.7412 - val_loss: 1.6319 - val_acc: 0.5554\n","Epoch 16/20\n","125/125 [==============================] - 2s 19ms/step - loss: 0.6875 - acc: 0.7628 - val_loss: 1.6508 - val_acc: 0.5691\n","Epoch 17/20\n","125/125 [==============================] - 2s 16ms/step - loss: 0.6272 - acc: 0.7851 - val_loss: 1.7695 - val_acc: 0.5566\n","Epoch 18/20\n","125/125 [==============================] - 1s 12ms/step - loss: 0.5933 - acc: 0.8006 - val_loss: 1.7620 - val_acc: 0.5586\n","Epoch 19/20\n","125/125 [==============================] - 1s 11ms/step - loss: 0.5324 - acc: 0.8175 - val_loss: 2.0026 - val_acc: 0.5614\n","Epoch 20/20\n","125/125 [==============================] - 2s 16ms/step - loss: 0.5000 - acc: 0.8279 - val_loss: 1.8217 - val_acc: 0.5714\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fa0a6f9d1e0>"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"KW8w16t_IrHY"},"source":["<font color='green'>**Pregunta 6 (1 punto): ¿Por qué usamos convoluciones de 1 dimensión para procesar texto?**</font>"]},{"cell_type":"markdown","source":["<font color='green'>Tu respuesta aqui:\n","\n","Las convoluciones de 1D son especialmente útiles para extraer características relevantes en datos secuenciales, como el texto, ya que pueden detectar patrones locales en diferentes posiciones dentro de la secuencia.   \n","Facilita el aprendizaje de características relevantes para tareas de clasificación, generación de texto y otras aplicaciones de procesamiento de lenguaje natural. Estas capas son capaces de capturar patrones locales en secuencias de texto, como frases, n-gramas y combinaciones de palabras adyacentes."],"metadata":{"id":"7H8RJNrHgjAU"}},{"cell_type":"markdown","metadata":{"id":"q3QVIb84Olda"},"source":["#Creación del modelo con un embedding hecho a mano con redes neuronales clásicas\n","\n","\n","\n"]},{"cell_type":"markdown","source":["<font color='green'>**Pregunta 7 (2 puntos): Crea un nuevo modelo partiendo del model anterior pero en lugar de Redes Neuronales Convolucionales vamos a utilizar Redes Neuronales Clásicas. Para ello, tras la capa Embedding añade una capa Flatten, una capa densa de 512 neuronas con función de activación relu y una capa Dropout de regulización al 30%. Por último, no olvides incluir la capa de salida con tantas neuronas como clases haya y la función de activación softmax.**</font>"],"metadata":{"id":"3olUvuUVLc4U"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UxNDppZYTLOb"},"outputs":[],"source":["# Tu código aqui\n","\n","modeloEmbeddingManualClasicas = keras.models.Sequential()\n","modeloEmbeddingManualClasicas.add(keras.layers.Embedding(20000, 10, input_length=200))\n","modeloEmbeddingManualClasicas.add(keras.layers.Flatten())\n","modeloEmbeddingManualClasicas.add(keras.layers.Dense(512, activation='relu'))\n","modeloEmbeddingManualClasicas.add(keras.layers.Dropout(0.3))\n","modeloEmbeddingManualClasicas.add(keras.layers.Dense(20, activation='softmax'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qD_hqn2sOlda","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685899790194,"user_tz":-120,"elapsed":82535,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}},"outputId":"42711fa8-5edb-4b5d-8a93-8ab184b931c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","125/125 [==============================] - 14s 105ms/step - loss: 2.8922 - acc: 0.0993 - val_loss: 2.6457 - val_acc: 0.1610\n","Epoch 2/20\n","125/125 [==============================] - 10s 82ms/step - loss: 2.3133 - acc: 0.2471 - val_loss: 2.1050 - val_acc: 0.2998\n","Epoch 3/20\n","125/125 [==============================] - 8s 66ms/step - loss: 1.6866 - acc: 0.4643 - val_loss: 1.6157 - val_acc: 0.4516\n","Epoch 4/20\n","125/125 [==============================] - 6s 52ms/step - loss: 1.1618 - acc: 0.6414 - val_loss: 1.3182 - val_acc: 0.5451\n","Epoch 5/20\n","125/125 [==============================] - 5s 38ms/step - loss: 0.8090 - acc: 0.7612 - val_loss: 1.1352 - val_acc: 0.6149\n","Epoch 6/20\n","125/125 [==============================] - 3s 24ms/step - loss: 0.5597 - acc: 0.8434 - val_loss: 1.0490 - val_acc: 0.6432\n","Epoch 7/20\n","125/125 [==============================] - 5s 41ms/step - loss: 0.4050 - acc: 0.8850 - val_loss: 1.0020 - val_acc: 0.6647\n","Epoch 8/20\n","125/125 [==============================] - 3s 23ms/step - loss: 0.3011 - acc: 0.9147 - val_loss: 0.9940 - val_acc: 0.6774\n","Epoch 9/20\n","125/125 [==============================] - 2s 16ms/step - loss: 0.2311 - acc: 0.9345 - val_loss: 1.0331 - val_acc: 0.6767\n","Epoch 10/20\n","125/125 [==============================] - 2s 16ms/step - loss: 0.1887 - acc: 0.9448 - val_loss: 1.0381 - val_acc: 0.6867\n","Epoch 11/20\n","125/125 [==============================] - 3s 24ms/step - loss: 0.1574 - acc: 0.9524 - val_loss: 1.0636 - val_acc: 0.6872\n","Epoch 12/20\n","125/125 [==============================] - 3s 22ms/step - loss: 0.1371 - acc: 0.9561 - val_loss: 1.1091 - val_acc: 0.6899\n","Epoch 13/20\n","125/125 [==============================] - 1s 11ms/step - loss: 0.1234 - acc: 0.9594 - val_loss: 1.1276 - val_acc: 0.6952\n","Epoch 14/20\n","125/125 [==============================] - 2s 13ms/step - loss: 0.1123 - acc: 0.9616 - val_loss: 1.1682 - val_acc: 0.6917\n","Epoch 15/20\n","125/125 [==============================] - 1s 10ms/step - loss: 0.1048 - acc: 0.9626 - val_loss: 1.1681 - val_acc: 0.6974\n","Epoch 16/20\n","125/125 [==============================] - 1s 7ms/step - loss: 0.0973 - acc: 0.9659 - val_loss: 1.1824 - val_acc: 0.7007\n","Epoch 17/20\n","125/125 [==============================] - 1s 11ms/step - loss: 0.0934 - acc: 0.9655 - val_loss: 1.2406 - val_acc: 0.6894\n","Epoch 18/20\n","125/125 [==============================] - 1s 11ms/step - loss: 0.0898 - acc: 0.9649 - val_loss: 1.2496 - val_acc: 0.6827\n","Epoch 19/20\n","125/125 [==============================] - 2s 13ms/step - loss: 0.0863 - acc: 0.9654 - val_loss: 1.2519 - val_acc: 0.6972\n","Epoch 20/20\n","125/125 [==============================] - 1s 8ms/step - loss: 0.0845 - acc: 0.9669 - val_loss: 1.2440 - val_acc: 0.6959\n","Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (None, 200, 10)           200000    \n","                                                                 \n"," flatten (Flatten)           (None, 2000)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 512)               1024512   \n","                                                                 \n"," dropout_1 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 20)                10260     \n","                                                                 \n","=================================================================\n","Total params: 1,234,772\n","Trainable params: 1,234,772\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}],"source":["modeloEmbeddingManualClasicas.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","modeloEmbeddingManualClasicas.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n","modeloEmbeddingManualClasicas.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))\n","print(modeloEmbeddingManualClasicas.summary())"]},{"cell_type":"markdown","source":["Tras hacer este experimento, es posible que pase una cosa curiosa y es que la red totalmente conectada tenga un mejor comportamiento que la convolucional. \n","En general, las redes neuronales convolucionales tienden a superar a las totalmente conectadas en la mayoría de los problemas de este tipo debido a su capacidad para capturar patrones espaciales y posicionales en los datos de entrada. Dicho esto, en algunos casos, una red neuronal clásica podría superar a una convolucional en un problema de procesamiento de lenguaje natural, especialmente si el conjunto de datos es pequeño y las características relevantes son relativamente simples. En este caso, la mayoría de las categorías puede ser que tengan un vocabulario específico y esa pueda ser una de las razones. \n","\n","\n","\n"],"metadata":{"id":"27PnPdfGMgQA"}},{"cell_type":"markdown","metadata":{"id":"DZL7wt0r_9Os"},"source":["#Creación del modelo con el embedding GloVe y redes neuronales convolucionales\n"]},{"cell_type":"markdown","source":["Esta vez, en vez de crear nosotros mismos el embedding, vamos a utilizar Glove. Los vectores de palabras generados por GloVe capturan las relaciones semánticas y sintácticas entre las palabras en un corpus de texto mucho más grande que el nuestro. "],"metadata":{"id":"XAvOGIybNH-C"}},{"cell_type":"code","source":["!wget http://nlp.stanford.edu/data/glove.6B.zip\n","!unzip -q glove.6B.zip"],"metadata":{"id":"xkzAfY0v72EM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"81192da0-e3a8-4778-b288-9b9de5abcb28","executionInfo":{"status":"ok","timestamp":1685986749483,"user_tz":-120,"elapsed":192627,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}}},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-06-05 17:35:56--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2023-06-05 17:35:56--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n","--2023-06-05 17:35:57--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: ‘glove.6B.zip’\n","\n","glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n","\n","2023-06-05 17:38:36 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n","\n"]}]},{"cell_type":"markdown","source":["<font color='green'>**Pregunta 8 (1 puntos): \tEl embedding que usa la actividad es el glove.6B. ¿De dónde se han obtenido los textos que se han usado para entrenarlo? ¿Cántos WordVectors lo componen? ¿De cuántas dimensiones tiene versiones? Puedes ayudarte del link https://nlp.stanford.edu/projects/glove/ para buscar la información**</font>\n","\n","\n"],"metadata":{"id":"xOf0LXFuOJBG"}},{"cell_type":"markdown","source":["<font color='green'>Tu respuesta aqui:\n","\n"," El corpus de texto utilizado para entrenar los vectores de palabras proviene de Wikipedia 2014 y Gigaword 5, que es un conjunto de noticias en inglés.  \n"," Consta de 400.000 vectores de palabras únicos.  \n"," Tiene versiones en 4 dimensiones distintas: 50, 100, 200 y 300.  \n"," "],"metadata":{"id":"C5Ht7roJai9D"}},{"cell_type":"code","execution_count":24,"metadata":{"id":"m-bSZXrqoAEg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685986755353,"user_tz":-120,"elapsed":5888,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}},"outputId":"31c7c130-4d17-4713-f8a9-cc7b3b628a76"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 400000 word vectors.\n"]}],"source":["path_to_glove_file = os.path.join(\n","    os.path.expanduser(\"~\"), \".keras/datasets/glove.6B.100d.txt\"\n",")\n","path_to_glove_file = \"glove.6B.100d.txt\"\n","embeddings_index = {}\n","with open(path_to_glove_file) as f:\n","    for line in f:\n","        word, coefs = line.split(maxsplit=1)\n","        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n","        embeddings_index[word] = coefs\n","\n","print(\"Found %s word vectors.\" % len(embeddings_index))"]},{"cell_type":"markdown","source":["Creamos la capa Embedding de keras. Se trata de una matrix numpy donde el valor de cada posición corresponde con el vector pre-entreneado del vocabulario tras el vectorizer"],"metadata":{"id":"UdKbdVax2e_l"}},{"cell_type":"code","execution_count":25,"metadata":{"id":"R2Tov2B6oBuF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685986778647,"user_tz":-120,"elapsed":329,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}},"outputId":"0ff05aae-1221-4f95-ff33-1fa70c345172"},"outputs":[{"output_type":"stream","name":"stdout","text":["Converted 18025 words (1975 misses)\n"]}],"source":["num_tokens = len(voc) + 2\n","embedding_dim = 100\n","hits = 0\n","misses = 0\n","\n","# Prepare embedding matrix\n","embedding_matrix = np.zeros((num_tokens, embedding_dim))\n","for word, i in word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        # Words not found in embedding index will be all-zeros.\n","        # This includes the representation for \"padding\" and \"OOV\"\n","        embedding_matrix[i] = embedding_vector\n","        hits += 1\n","    else:\n","        misses += 1\n","print(\"Converted %d words (%d misses)\" % (hits, misses))"]},{"cell_type":"markdown","source":["Cargamos el embedding como una capa keras. Al poner trainable=False nos quedamos con los valores del modelo pre-entrenado, es decir, no actualizamos estos valores a lo largo del entrenamiento"],"metadata":{"id":"akWSH27b21AY"}},{"cell_type":"code","execution_count":26,"metadata":{"id":"w40nHAAPoD0J","executionInfo":{"status":"ok","timestamp":1685986780568,"user_tz":-120,"elapsed":198,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}}},"outputs":[],"source":["from tensorflow.keras.layers import Embedding\n","\n","embedding_layer = Embedding(\n","    num_tokens,\n","    embedding_dim,\n","    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n","    trainable=False,\n",")"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"UoPboJ6l_9Ot","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685986782503,"user_tz":-120,"elapsed":520,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}},"outputId":"592fe9e2-d4c5-4b01-ac71-15563f1747f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," embedding_1 (Embedding)     (None, None, 100)         2000200   \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, None, 128)         64128     \n","                                                                 \n"," max_pooling1d_2 (MaxPooling  (None, None, 128)        0         \n"," 1D)                                                             \n","                                                                 \n"," conv1d_4 (Conv1D)           (None, None, 128)         82048     \n","                                                                 \n"," max_pooling1d_3 (MaxPooling  (None, None, 128)        0         \n"," 1D)                                                             \n","                                                                 \n"," conv1d_5 (Conv1D)           (None, None, 128)         82048     \n","                                                                 \n"," global_max_pooling1d_1 (Glo  (None, 128)              0         \n"," balMaxPooling1D)                                                \n","                                                                 \n"," dense_2 (Dense)             (None, 128)               16512     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 20)                2580      \n","                                                                 \n","=================================================================\n","Total params: 2,247,516\n","Trainable params: 247,316\n","Non-trainable params: 2,000,200\n","_________________________________________________________________\n"]}],"source":["from tensorflow.keras import layers\n","\n","int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n","embedded_sequences = embedding_layer(int_sequences_input)\n","x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n","x = layers.MaxPooling1D(5)(x)\n","x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n","x = layers.MaxPooling1D(5)(x)\n","x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n","x = layers.GlobalMaxPooling1D()(x)\n","x = layers.Dense(128, activation=\"relu\")(x)\n","x = layers.Dropout(0.5)(x)\n","preds = layers.Dense(len(class_names), activation=\"softmax\")(x)\n","modelEmbeddingGloveConvolucionales = keras.Model(int_sequences_input, preds)\n","modelEmbeddingGloveConvolucionales.summary()\n"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"nllcCJY__9Ot","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685986827732,"user_tz":-120,"elapsed":42717,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}},"outputId":"725cfa86-c230-4f3d-8866-2e94a5d3cb50"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","125/125 [==============================] - 3s 12ms/step - loss: 2.6678 - acc: 0.1399 - val_loss: 2.1462 - val_acc: 0.2543\n","Epoch 2/20\n","125/125 [==============================] - 1s 8ms/step - loss: 1.9319 - acc: 0.3347 - val_loss: 1.5054 - val_acc: 0.5034\n","Epoch 3/20\n","125/125 [==============================] - 1s 8ms/step - loss: 1.5050 - acc: 0.4875 - val_loss: 1.4161 - val_acc: 0.5221\n","Epoch 4/20\n","125/125 [==============================] - 1s 8ms/step - loss: 1.2671 - acc: 0.5683 - val_loss: 1.3099 - val_acc: 0.5456\n","Epoch 5/20\n","125/125 [==============================] - 1s 9ms/step - loss: 1.0978 - acc: 0.6215 - val_loss: 1.1866 - val_acc: 0.5911\n","Epoch 6/20\n","125/125 [==============================] - 1s 9ms/step - loss: 0.9788 - acc: 0.6632 - val_loss: 1.1124 - val_acc: 0.6324\n","Epoch 7/20\n","125/125 [==============================] - 1s 8ms/step - loss: 0.8568 - acc: 0.7082 - val_loss: 1.0394 - val_acc: 0.6462\n","Epoch 8/20\n","125/125 [==============================] - 1s 8ms/step - loss: 0.7476 - acc: 0.7437 - val_loss: 0.9972 - val_acc: 0.6717\n","Epoch 9/20\n","125/125 [==============================] - 1s 8ms/step - loss: 0.6566 - acc: 0.7723 - val_loss: 1.0328 - val_acc: 0.6609\n","Epoch 10/20\n","125/125 [==============================] - 1s 8ms/step - loss: 0.5711 - acc: 0.8015 - val_loss: 1.0113 - val_acc: 0.6839\n","Epoch 11/20\n","125/125 [==============================] - 1s 8ms/step - loss: 0.4958 - acc: 0.8273 - val_loss: 1.0727 - val_acc: 0.6757\n","Epoch 12/20\n","125/125 [==============================] - 1s 8ms/step - loss: 0.4400 - acc: 0.8490 - val_loss: 1.0785 - val_acc: 0.6854\n","Epoch 13/20\n","125/125 [==============================] - 1s 9ms/step - loss: 0.3776 - acc: 0.8719 - val_loss: 1.1765 - val_acc: 0.6724\n","Epoch 14/20\n","125/125 [==============================] - 1s 8ms/step - loss: 0.3264 - acc: 0.8882 - val_loss: 1.1449 - val_acc: 0.6909\n","Epoch 15/20\n","125/125 [==============================] - 1s 8ms/step - loss: 0.2977 - acc: 0.9002 - val_loss: 1.1382 - val_acc: 0.6952\n","Epoch 16/20\n","125/125 [==============================] - 1s 9ms/step - loss: 0.2643 - acc: 0.9084 - val_loss: 1.2573 - val_acc: 0.6729\n","Epoch 17/20\n","125/125 [==============================] - 1s 10ms/step - loss: 0.2427 - acc: 0.9211 - val_loss: 1.2274 - val_acc: 0.6939\n","Epoch 18/20\n","125/125 [==============================] - 1s 9ms/step - loss: 0.2183 - acc: 0.9266 - val_loss: 1.4429 - val_acc: 0.6702\n","Epoch 19/20\n","125/125 [==============================] - 1s 8ms/step - loss: 0.1954 - acc: 0.9357 - val_loss: 1.5403 - val_acc: 0.6777\n","Epoch 20/20\n","125/125 [==============================] - 1s 8ms/step - loss: 0.1823 - acc: 0.9375 - val_loss: 1.8170 - val_acc: 0.6709\n","125/125 [==============================] - 1s 3ms/step\n"]}],"source":["modelEmbeddingGloveConvolucionales.compile(    loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n","modelEmbeddingGloveConvolucionales.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))\n","predictions = modelEmbeddingGloveConvolucionales.predict(x_val)"]},{"cell_type":"markdown","source":["#Creación del modelo final\n"],"metadata":{"id":"YySP5H70BQcx"}},{"cell_type":"markdown","source":["<font color='green'>**Pregunta 9 (1 puntos): \tA estas alturas ya te habrás dado cuenta que los Transformer que has utilizado en la asignatura de Procesamiento de Lenguaje Natural son, probablemente, los que mejores resultados obtienen. Sin utilizar Transformer, crea un modelo tú, bien ajustando los hiperparámetros de los modelos anteriores o uno completamente nuevo, que llegue al menos al 72% accuracy**</font>"],"metadata":{"id":"oo0aRSmoOz6s"}},{"cell_type":"code","source":["from tensorflow.keras import layers, models\n"," \n","# Definir la longitud máxima de las secuencias de entrada\n","sequence_length = x_train.shape[1]\n"," \n","# Crear el modelo\n","model = models.Sequential()\n","model.add(layers.Embedding(num_tokens, embedding_dim, input_length=sequence_length))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(512, activation='relu'))\n","model.add(layers.Dropout(0.3))\n","model.add(layers.Dense(len(class_names), activation='softmax'))"],"metadata":{"id":"Dyy9CPpCGmbL","executionInfo":{"status":"ok","timestamp":1685987178490,"user_tz":-120,"elapsed":206,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# Compilar el modelo\n","model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Resumen del modelo\n","model.summary()\n","\n","# Entrenar el modelo\n","history = model.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))\n","\n","# Obtener las predicciones\n","predictions = model.predict(x_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LpibJtBfqghD","executionInfo":{"status":"ok","timestamp":1685987322688,"user_tz":-120,"elapsed":143288,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}},"outputId":"92433062-12e4-4a0d-c7e7-941cf1ec49f8"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_2 (Embedding)     (None, 200, 100)          2000200   \n","                                                                 \n"," flatten (Flatten)           (None, 20000)             0         \n","                                                                 \n"," dense_4 (Dense)             (None, 512)               10240512  \n","                                                                 \n"," dropout_2 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_5 (Dense)             (None, 20)                10260     \n","                                                                 \n","=================================================================\n","Total params: 12,250,972\n","Trainable params: 12,250,972\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/20\n","125/125 [==============================] - 20s 146ms/step - loss: 2.6998 - accuracy: 0.1498 - val_loss: 2.2407 - val_accuracy: 0.2648\n","Epoch 2/20\n","125/125 [==============================] - 13s 107ms/step - loss: 1.5094 - accuracy: 0.5553 - val_loss: 1.4942 - val_accuracy: 0.5121\n","Epoch 3/20\n","125/125 [==============================] - 10s 78ms/step - loss: 0.6101 - accuracy: 0.8530 - val_loss: 1.2567 - val_accuracy: 0.5974\n","Epoch 4/20\n","125/125 [==============================] - 10s 80ms/step - loss: 0.2816 - accuracy: 0.9337 - val_loss: 1.2053 - val_accuracy: 0.6169\n","Epoch 5/20\n","125/125 [==============================] - 7s 51ms/step - loss: 0.1756 - accuracy: 0.9561 - val_loss: 1.2569 - val_accuracy: 0.6029\n","Epoch 6/20\n","125/125 [==============================] - 6s 49ms/step - loss: 0.1328 - accuracy: 0.9616 - val_loss: 1.2488 - val_accuracy: 0.6177\n","Epoch 7/20\n","125/125 [==============================] - 5s 38ms/step - loss: 0.1137 - accuracy: 0.9644 - val_loss: 1.2612 - val_accuracy: 0.6287\n","Epoch 8/20\n","125/125 [==============================] - 4s 29ms/step - loss: 0.1025 - accuracy: 0.9661 - val_loss: 1.2815 - val_accuracy: 0.6244\n","Epoch 9/20\n","125/125 [==============================] - 3s 27ms/step - loss: 0.0939 - accuracy: 0.9659 - val_loss: 1.2966 - val_accuracy: 0.6244\n","Epoch 10/20\n","125/125 [==============================] - 3s 24ms/step - loss: 0.0879 - accuracy: 0.9660 - val_loss: 1.3113 - val_accuracy: 0.6327\n","Epoch 11/20\n","125/125 [==============================] - 3s 27ms/step - loss: 0.0820 - accuracy: 0.9671 - val_loss: 1.2999 - val_accuracy: 0.6377\n","Epoch 12/20\n","125/125 [==============================] - 2s 17ms/step - loss: 0.0784 - accuracy: 0.9664 - val_loss: 1.3125 - val_accuracy: 0.6312\n","Epoch 13/20\n","125/125 [==============================] - 3s 22ms/step - loss: 0.0741 - accuracy: 0.9681 - val_loss: 1.3273 - val_accuracy: 0.6339\n","Epoch 14/20\n","125/125 [==============================] - 3s 22ms/step - loss: 0.0705 - accuracy: 0.9696 - val_loss: 1.3399 - val_accuracy: 0.6337\n","Epoch 15/20\n","125/125 [==============================] - 2s 16ms/step - loss: 0.0688 - accuracy: 0.9686 - val_loss: 1.3482 - val_accuracy: 0.6317\n","Epoch 16/20\n","125/125 [==============================] - 1s 11ms/step - loss: 0.0680 - accuracy: 0.9694 - val_loss: 1.3182 - val_accuracy: 0.6364\n","Epoch 17/20\n","125/125 [==============================] - 1s 9ms/step - loss: 0.0651 - accuracy: 0.9689 - val_loss: 1.3148 - val_accuracy: 0.6412\n","Epoch 18/20\n","125/125 [==============================] - 2s 16ms/step - loss: 0.0626 - accuracy: 0.9687 - val_loss: 1.3413 - val_accuracy: 0.6382\n","Epoch 19/20\n","125/125 [==============================] - 1s 11ms/step - loss: 0.0606 - accuracy: 0.9692 - val_loss: 1.3568 - val_accuracy: 0.6322\n","Epoch 20/20\n","125/125 [==============================] - 2s 14ms/step - loss: 0.0612 - accuracy: 0.9697 - val_loss: 1.3395 - val_accuracy: 0.6332\n","125/125 [==============================] - 0s 1ms/step\n"]}]},{"cell_type":"code","source":["model.evaluate(x_val, y_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h4xxecxTsX8P","executionInfo":{"status":"ok","timestamp":1685987735243,"user_tz":-120,"elapsed":491,"user":{"displayName":"salvelpr","userId":"03936313709350824429"}},"outputId":"84059402-d7c1-4ba7-f1f5-a6d79b4277f1"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["125/125 [==============================] - 0s 2ms/step - loss: 1.3395 - accuracy: 0.6332\n"]},{"output_type":"execute_result","data":{"text/plain":["[1.3395164012908936, 0.633158266544342]"]},"metadata":{},"execution_count":32}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}